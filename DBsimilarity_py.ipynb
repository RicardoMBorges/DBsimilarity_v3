{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1ff5330",
   "metadata": {},
   "source": [
    "# DBsimilarity — Basics in Chemometrics\n",
    "\n",
    "Computational methods are now core to natural products research, especially when dealing with **unfractionated extracts** where signal overlap and chemical diversity complicate classic workflows. **Chemoinformatics** helps turn raw structures into actionable knowledge for:\n",
    "\n",
    "* specimen prioritization,\n",
    "* hypothesis generation for biological activity,\n",
    "* biosynthetic and taxonomic inference,\n",
    "* and rapid *in silico* dereplication.\n",
    "\n",
    "## Goal of this notebook\n",
    "\n",
    "Provide a clear, reproducible, end-to-end path that turns structure files into analysis-ready artifacts for MS/NMR dereplication and chemical space exploration—without requiring advanced programming skills.\n",
    "\n",
    "## What you’ll do (overview)\n",
    "\n",
    "1. **Convert** structural libraries (e.g., `.sdf`) to tidy **`.csv`** tables.\n",
    "2. **Organize** data into a single Pandas **DataFrame** with consistent identifiers.\n",
    "3. **Annotate** each SMILES with chemoinformatics fields (InChI, InChIKey, formula, exact mass, adduct m/z, SLogP).\n",
    "4. **Build a custom MS database** (MZmine-style) for rapid **MS1 dereplication**.\n",
    "5. **Assemble candidate lists for 2D NMR** dereplication (e.g., to support HSQC/TOCSY workflows).\n",
    "6. **Quantify similarity** between compounds (Morgan fingerprints) and **cluster** using descriptors.\n",
    "7. **Construct similarity networks** and export edge lists ready for **Cytoscape**.\n",
    "\n",
    "Along the way you’ll also generate **MassQL** queries (MS1 and MS2) to search vendor-agnostic LC-MS(/MS) datasets, compute **Mordred** descriptors, run **hierarchical clustering** and **t-SNE** projections to visualize chemical space.\n",
    "\n",
    "## Who this is for\n",
    "\n",
    "Researchers who want practical, readable notebooks to:\n",
    "\n",
    "* understand what’s in a specimen-specific compound list,\n",
    "* create reusable MS/NMR dereplication assets,\n",
    "* and explore chemical diversity with minimal coding.\n",
    "\n",
    "## Inputs & outputs (at a glance)\n",
    "\n",
    "* **Input:** structure files (`.sdf`) or tables (`.csv`) with at least names and SMILES.\n",
    "* **Outputs:**\n",
    "\n",
    "  * Annotated compound table (InChI, InChIKey, formula, exact mass, adduct m/z, SLogP)\n",
    "  * MZmine custom DB CSV (MS1)\n",
    "  * MassQL query files (MS1 and MS2)\n",
    "  * Descriptor tables (Mordred) + dendrogram PNG + clustering CSV\n",
    "  * t-SNE HTML plot (interactive)\n",
    "  * Similarity network edge list + isolated nodes CSV (for Cytoscape)\n",
    "\n",
    "## Minimal prerequisites\n",
    "\n",
    "* **Python** (conda environment recommended)\n",
    "* Core libraries: `pandas`, `numpy`, `matplotlib`, `scipy`, `scikit-learn`, `networkx`\n",
    "* **RDKit** for structure parsing and fingerprints\n",
    "* **Mordred** (optional) for extended descriptors\n",
    "* **Plotly** (optional) for interactive t-SNE\n",
    "* **Cytoscape** (optional) for network visualization\n",
    "\n",
    "> Tip: Some RDKit/Mordred builds prefer `numpy<2`. If descriptor steps fail, pin NumPy accordingly.\n",
    "\n",
    "## Learn more\n",
    "\n",
    "* Pandas: [https://pandas.pydata.org/](https://pandas.pydata.org/)\n",
    "* RDKit (Getting Started in Python): [https://www.rdkit.org/docs/GettingStartedInPython.html](https://www.rdkit.org/docs/GettingStartedInPython.html)\n",
    "* ChEMBL web services: [https://chembl.gitbook.io/chembl-interface-documentation/web-services](https://chembl.gitbook.io/chembl-interface-documentation/web-services)\n",
    "* Mordred: [http://mordred-descriptor.github.io/documentation/master/](http://mordred-descriptor.github.io/documentation/master/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45e6d7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded dbsimilarity_2 as dbs\n",
      "Python : 3.11.6\n",
      "Pandas : 1.5.3\n",
      "NumPy  : 1.23.5\n",
      "RDKit  : 2022.09.5\n",
      "Mordred: OK\n",
      "Plotly : OK\n",
      "PandasTools: OK\n"
     ]
    }
   ],
   "source": [
    "# --- Toggles (flip as you like) ---\n",
    "USE_NBAGG          = True   # interactive matplotlib in Jupyter (fallbacks if unsupported)\n",
    "ENABLE_PANDAS_TOOLS= True   # RDKit PandasTools (adds Molecule column helpers)\n",
    "ENABLE_MORDRED     = True   # set False if not installed\n",
    "ENABLE_CHEMBL      = False  # set True if you plan to query ChEMBL\n",
    "\n",
    "# --- Stdlib & core libs ---\n",
    "import os, sys, warnings, platform\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pandas display niceties\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 180)\n",
    "pd.set_option(\"display.float_format\", lambda x: f\"{x:.6g}\")\n",
    "\n",
    "# --- RDKit (don’t alias AllChem as Chem!) ---\n",
    "try:\n",
    "    from rdkit import RDLogger, Chem\n",
    "    RDLogger.DisableLog('rdApp.*')          # silence verbose RDKit logs\n",
    "    from rdkit.Chem import AllChem          # fingerprints, conformers\n",
    "    from rdkit.Chem import Descriptors as RDDesc\n",
    "    from rdkit.Chem.rdMolDescriptors import CalcMolFormula\n",
    "    from rdkit import DataStructs\n",
    "    RDKIT_OK = True\n",
    "except Exception as e:\n",
    "    RDKIT_OK = False\n",
    "    print(\"⚠️ RDKit not available:\", e)\n",
    "\n",
    "# RDKit PandasTools (optional, controlled by toggle)\n",
    "HAS_PANDAS_TOOLS = False\n",
    "if ENABLE_PANDAS_TOOLS and RDKIT_OK:\n",
    "    try:\n",
    "        from rdkit.Chem import PandasTools\n",
    "        HAS_PANDAS_TOOLS = True\n",
    "    except Exception as e:\n",
    "        print(\"ℹ️ RDKit PandasTools not available (continuing without it):\", e)\n",
    "\n",
    "# --- Mordred (optional) ---\n",
    "if ENABLE_MORDRED:\n",
    "    try:\n",
    "        from mordred import Calculator, descriptors\n",
    "        MORDRED_OK = True\n",
    "    except Exception as e:\n",
    "        MORDRED_OK = False\n",
    "        print(\"⚠️ Mordred not available:\", e)\n",
    "else:\n",
    "    MORDRED_OK = False\n",
    "\n",
    "# --- Plotting ---\n",
    "import matplotlib\n",
    "if USE_NBAGG:\n",
    "    try:\n",
    "        matplotlib.use('nbagg')  # interactive zoom when supported\n",
    "    except Exception:\n",
    "        pass\n",
    "import matplotlib.pyplot as plt\n",
    "try:\n",
    "    import seaborn as sns\n",
    "    sns.set_context(\"notebook\")\n",
    "    sns.set_style(\"ticks\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# --- Plotly (optional, for interactive HTML like t-SNE) ---\n",
    "try:\n",
    "    import plotly\n",
    "    PLOTLY_OK = True\n",
    "except Exception as e:\n",
    "    PLOTLY_OK = False\n",
    "    print(\"ℹ️ Plotly not available (only affects interactive HTML exports):\", e)\n",
    "\n",
    "# --- Networks & misc ---\n",
    "import networkx as nx\n",
    "try:\n",
    "    from wordcloud import WordCloud\n",
    "except Exception:\n",
    "    WordCloud = None\n",
    "\n",
    "# --- ChEMBL client (optional) ---\n",
    "if ENABLE_CHEMBL:\n",
    "    try:\n",
    "        from chembl_webresource_client.new_client import new_client\n",
    "    except Exception as e:\n",
    "        print(\"ℹ️ ChEMBL client not available (skipping):\", e)\n",
    "        new_client = None\n",
    "else:\n",
    "    new_client = None\n",
    "\n",
    "# --- Project paths ---\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "DATA_DIR     = PROJECT_ROOT / \"data\"\n",
    "IMAGES_DIR   = PROJECT_ROOT / \"images\"\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "IMAGES_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# --- Import your tools ---\n",
    "# Prefer local project modules; fall back to the generic chem tools if present.\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "sys.path.append(str(PROJECT_ROOT.parent))\n",
    "\n",
    "dbs = None\n",
    "ct  = None\n",
    "try:\n",
    "    sys.path.insert(0, os.path.abspath('..'))\n",
    "    import dbsimilarity_2 as dbs\n",
    "    print(\"✅ Loaded dbsimilarity_2 as dbs\")\n",
    "except Exception as e:\n",
    "    print(\"ℹ️ Could not import dbsimilarity_2:\", e)\n",
    "\n",
    "\n",
    "aliases = {\n",
    "    \"SMILES\":   [\"SMILES\", \"smiles\", \"***smiles***\", \"Smiles\", \"Smiles_parent\"],\n",
    "    \"InChIKey\": [\"InChIKey\", \"INCHIKEY\", \"inchikey\", \"InChlKey\", \"InChI Key\", \"INCHI_KEY\"],\n",
    "    \"Compound name\": [\"Compound name\", \"Name\", \"Compound\", \"compound_name\"],\n",
    "}        \n",
    "\n",
    "# --- Quick environment summary ---\n",
    "def env_summary():\n",
    "    print(\"Python :\", platform.python_version())\n",
    "    print(\"Pandas :\", pd.__version__)\n",
    "    print(\"NumPy  :\", np.__version__)\n",
    "    if RDKIT_OK:\n",
    "        try:\n",
    "            from rdkit.rdBase import rdkitVersion\n",
    "            print(\"RDKit  :\", rdkitVersion)\n",
    "        except Exception:\n",
    "            print(\"RDKit  : OK (version not available)\")\n",
    "    else:\n",
    "        print(\"RDKit  :\", \"missing\")\n",
    "    print(\"Mordred:\", \"OK\" if MORDRED_OK else \"missing/disabled\")\n",
    "    print(\"Plotly :\", \"OK\" if PLOTLY_OK else \"missing/disabled\")\n",
    "    print(\"PandasTools:\", \"OK\" if HAS_PANDAS_TOOLS else \"missing/disabled\")\n",
    "\n",
    "env_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33731c82",
   "metadata": {},
   "source": [
    "### Set the project name from the folder you’re working in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0868d0c8-12a3-4773-a175-eb15affabee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cyanobacteria'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the current working directory\n",
    "current_directory = %pwd\n",
    "\n",
    "# Extract the last folder from the path\n",
    "last_folder = os.path.basename(current_directory)\n",
    "Project = last_folder\n",
    "\n",
    "Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fe6cee",
   "metadata": {},
   "source": [
    "### Load the target compound list and normalize identifiers\n",
    "\n",
    "This cell reads your **target list** from `Target+\".csv\"` (semicolon-separated) and derives a canonical **InChIKey** from each SMILES. Having InChIKeys up front makes downstream matching, deduplication, and network building reliable and ID-agnostic.\n",
    "\n",
    "Tips:\n",
    "\n",
    "* Make sure the CSV has a **`SMILES`** column (and optionally a name/ID column).\n",
    "* If your file uses a different delimiter or encoding, tweak `sep=\";\"` or add `encoding=\"utf-8\"`.\n",
    "* Invalid SMILES will raise errors later; consider filtering or reporting them here if needed.\n",
    "* If you already have an `InchiKey` column, you can skip recomputing—or recompute to ensure consistency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73651d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: CyanoMetDB.csv | sep=',' | encoding='utf-8' | rows=2122, cols=6\n",
      "Note: 7 rows have invalid/unparseable SMILES (InchiKey = NaN).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Compound identifier</th>\n",
       "      <th>Compound name</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>InChIKey</th>\n",
       "      <th>Fragments</th>\n",
       "      <th>InchiKey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CyanoMetDB_0002</td>\n",
       "      <td>Anhydrohapaloxindole B</td>\n",
       "      <td>O=C1NC2=CC=CC3=C2C1=C4[C@H]([C@@](C=C)([C@@H](...</td>\n",
       "      <td>POWOOZMDXKYYOK-FWKFCYAVSA-N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POWOOZMDXKYYOK-FWKFCYAVSA-N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CyanoMetDB_0003</td>\n",
       "      <td>Columbamide B</td>\n",
       "      <td>ClC(Cl)CCCCCC(Cl)CCCC/C=C/CCC(N(C)[C@@H](COC)C...</td>\n",
       "      <td>JBEYLLUXESVNSE-QOZDHKFNSA-N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JBEYLLUXESVNSE-QOZDHKFNSA-N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CyanoMetDB_0004</td>\n",
       "      <td>Columbamide C</td>\n",
       "      <td>ClCCCCCCC(Cl)CCCC/C=C/CCC(N(C)[C@@H](COC)CO)=O</td>\n",
       "      <td>HFTYBOHUADLAJY-KRTLOWCSSA-N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HFTYBOHUADLAJY-KRTLOWCSSA-N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Compound identifier            Compound name                                             SMILES                     InChIKey  Fragments                     InchiKey\n",
       "0      CyanoMetDB_0002  Anhydrohapaloxindole B  O=C1NC2=CC=CC3=C2C1=C4[C@H]([C@@](C=C)([C@@H](...  POWOOZMDXKYYOK-FWKFCYAVSA-N        NaN  POWOOZMDXKYYOK-FWKFCYAVSA-N\n",
       "1      CyanoMetDB_0003           Columbamide B  ClC(Cl)CCCCCC(Cl)CCCC/C=C/CCC(N(C)[C@@H](COC)C...  JBEYLLUXESVNSE-QOZDHKFNSA-N        NaN  JBEYLLUXESVNSE-QOZDHKFNSA-N\n",
       "2      CyanoMetDB_0004           Columbamide C     ClCCCCCCC(Cl)CCCC/C=C/CCC(N(C)[C@@H](COC)CO)=O  HFTYBOHUADLAJY-KRTLOWCSSA-N        NaN  HFTYBOHUADLAJY-KRTLOWCSSA-N"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Target = \"CyanoMetDB\"  # pass either a stem or filename with extension\n",
    "\n",
    "path = dbs._detect_file(Target)\n",
    "sep = dbs._guess_sep(path)\n",
    "df_target, used_encoding = dbs._read_table(path, sep=sep)\n",
    "smiles_col = dbs._normalize_smiles_column(df_target)\n",
    "\n",
    "df_target = dbs.rename_by_aliases(df_target, aliases, inplace=False, prefer=\"max_notna\")\n",
    "\n",
    "dbs._add_inchikey(df_target, smiles_col=\"SMILES\", out_col=\"InchiKey\")\n",
    "\n",
    "print(\n",
    "    f\"Loaded: {path.name} | sep='{sep}' | encoding='{used_encoding}' | \"\n",
    "    f\"rows={df_target.shape[0]}, cols={df_target.shape[1]}\"\n",
    ")\n",
    "invalid = df_target[\"InchiKey\"].isna().sum()\n",
    "if invalid:\n",
    "    print(f\"Note: {invalid} rows have invalid/unparseable SMILES (InchiKey = NaN).\")\n",
    "\n",
    "df_target.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cee976",
   "metadata": {},
   "source": [
    "### Load the reference (“compounds of interest”) database and standardize IDs\n",
    "\n",
    "This cell imports your curated reference set (e.g., CyanoMetDB / ChEMBL slice) from a semicolon-separated CSV encoded in **Latin-1**. It also fixes a common header typo by renaming **`InChlKey` → `InchiKey`**, so downstream joins and comparisons use a single, consistent identifier.\n",
    "\n",
    "Why it matters:\n",
    "\n",
    "* This table is your **search space** for dereplication and similarity checks against the target list.\n",
    "* Consistent **InchiKey** naming avoids silent merge failures later.\n",
    "\n",
    "Tips:\n",
    "\n",
    "* After loading, consider trimming whitespace and **deduplicating by `InchiKey`** to prevent double counting.\n",
    "* If you see weird characters, confirm the file’s encoding (utf-8 vs latin1) and delimiter (`sep=\";\"` here).\n",
    "* Keep column names aligned across tables (`SMILES`, `InchiKey`, `Compound name`, etc.) for smooth merges.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc197e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: CyanoNP2010-2023.csv | sep=',' | encoding='utf-8' | rows=995, cols=4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Fragments</th>\n",
       "      <th>InchiKey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4-hydroperoxyoscillatoxin B2</td>\n",
       "      <td>O=C(O[C@@H]([C@H](O)C)CC(O[C@H]([C@H](C)[C@H](...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QZGGIZIUEKEAAS-XRPLRUMHSA-N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17-bromo-4-hydroperoxyoscillatoxin B2</td>\n",
       "      <td>O=C(O[C@@H]([C@H](O)C)CC(O[C@H]([C@H](C)[C@H](...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IXKNJBBLNNUXPK-KASRWXAJSA-N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17-bromooscillatoxin B2</td>\n",
       "      <td>O=C(O[C@@H]([C@H](O)C)CC(O[C@H]([C@H](C)[C@H](...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YDMZOYPZIGUJJL-KASRWXAJSA-N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               file_path                                             SMILES  Fragments                     InchiKey\n",
       "0           4-hydroperoxyoscillatoxin B2  O=C(O[C@@H]([C@H](O)C)CC(O[C@H]([C@H](C)[C@H](...        NaN  QZGGIZIUEKEAAS-XRPLRUMHSA-N\n",
       "1  17-bromo-4-hydroperoxyoscillatoxin B2  O=C(O[C@@H]([C@H](O)C)CC(O[C@H]([C@H](C)[C@H](...        NaN  IXKNJBBLNNUXPK-KASRWXAJSA-N\n",
       "2                17-bromooscillatoxin B2  O=C(O[C@@H]([C@H](O)C)CC(O[C@H]([C@H](C)[C@H](...        NaN  YDMZOYPZIGUJJL-KASRWXAJSA-N"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Additional = \"CyanoNP2010-2023\"  # pass either a stem or filename with extension\n",
    "\n",
    "path = dbs._detect_file(Additional)\n",
    "sep = dbs._guess_sep(path)\n",
    "df_Additional, used_encoding = dbs._read_table(path, sep=sep)\n",
    "smiles_col = dbs._normalize_smiles_column(df_Additional)\n",
    "\n",
    "df_Additional = dbs.rename_by_aliases(df_Additional, aliases, inplace=False, prefer=\"max_notna\")\n",
    "\n",
    "dbs._add_inchikey(df_Additional, smiles_col=\"SMILES\", out_col=\"InchiKey\")\n",
    "\n",
    "print(\n",
    "    f\"Loaded: {path.name} | sep='{sep}' | encoding='{used_encoding}' | \"\n",
    "    f\"rows={df_Additional.shape[0]}, cols={df_Additional.shape[1]}\"\n",
    ")\n",
    "invalid = df_Additional[\"InchiKey\"].isna().sum()\n",
    "if invalid:\n",
    "    print(f\"Note: {invalid} rows have invalid/unparseable SMILES (InchiKey = NaN).\")\n",
    "\n",
    "df_Additional.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1874f4f",
   "metadata": {},
   "source": [
    "#### Clean and deduplicate the reference table\n",
    "\n",
    "This step removes unusable entries and redundancies before any joins or similarity work:\n",
    "\n",
    "* Converts empty `SMILES` strings to `NaN` and **drops missing** structures.\n",
    "* **Deduplicates** by `SMILES` to avoid double counting during stats, clustering, and network building.\n",
    "* Prints the table size **before/after** so you can audit the impact.\n",
    "\n",
    "Tips:\n",
    "\n",
    "* If tautomers/salts matter, consider normalizing SMILES (`Chem.MolToSmiles(..., canonical=True)`) or deduplicating by **InChIKey** instead of raw SMILES.\n",
    "* Optional: trim whitespace and standardize encoding before this step to catch edge cases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4534843-66b1-4b41-a5cc-e0cb1f4228ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the dataframe before filter empty cells: (995, 4).\n",
      "Size of the dataframe after filter empty and duplicated cells: (995, 4).\n"
     ]
    }
   ],
   "source": [
    "# Filter row for empty cells\n",
    "print(f\"Size of the dataframe before filter empty cells: {df_Additional.shape}.\")\n",
    "df_Additional[\"SMILES\"].replace('',np.nan,inplace=True)\n",
    "df_Additional.dropna(subset=\"SMILES\", inplace=True)\n",
    "# Remove duplicate rows based on the \"SMILES\" column\n",
    "df_Additional.drop_duplicates(subset=[\"SMILES\"], inplace=True)\n",
    "print(f\"Size of the dataframe after filter empty and duplicated cells: {df_Additional.shape}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4642e9",
   "metadata": {},
   "source": [
    "### Merge target and reference, then flag the overlap (“compounds of interest”)\n",
    "\n",
    "This cell unions the **target** list and the **reference** database on `InchiKey` using `merge_dataframes()`. That helper also adds presence flags:\n",
    "\n",
    "* `additional_column_1` → present in **df\\_target**\n",
    "* `additional_column_2` → present in **df\\_Additional_List**\n",
    "\n",
    "We then extract the **intersection**—compounds that occur in **both** tables—as `df_Interest`, and print a quick audit of sizes so you can see how many candidates are immediately dereplicated.\n",
    "\n",
    "Heads-up:\n",
    "\n",
    "* Use parentheses when filtering to avoid precedence gotchas:\n",
    "\n",
    "  ```python\n",
    "  df_Interest = merged_df.loc[(merged_df['additional_column_1'] == 1) & (merged_df['additional_column_2'] == 1)]\n",
    "  ```\n",
    "* Consider renaming the flags after merge (e.g., `in_target`, `in_reference`) for readability.\n",
    "* If stereochemistry/salt forms matter, `InchiKey` is a good join key; otherwise you may want to use standardized InChI or layer-specific keys depending on your workflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cd64b7a-3416-48c7-b610-75fffd1977e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the merged structure databases: df_target + df_Additional (3117) = 2709\n",
      "Size of the original structure database to study: 2122\n",
      "Size of the Additional structure database used as seed for compounds of interest: 995\n",
      "How many compounds can be promptly identified as compounds of interest (co-occurring in both databases): 383\n"
     ]
    }
   ],
   "source": [
    "# Combine both dataframes\n",
    "merged_df = dbs.merge_dataframes(\n",
    "    [df_target,df_Additional],\n",
    "    key_column=\"InchiKey\",\n",
    "    name_columns=[\"Compound name\", \"file_path\", \"Compound\"],\n",
    "    unified_name_col=\"Compound name (unified)\"\n",
    ")\n",
    "\n",
    "df_Interest = merged_df.loc[merged_df['additional_column_1'] & merged_df['additional_column_2'] == 1]\n",
    "print(f\"Size of the merged structure databases: df_target + df_Additional ({df_target.shape[0]+df_Additional.shape[0]}) = {merged_df.shape[0]}\")\n",
    "print(f\"Size of the original structure database to study: {df_target.shape[0]}\")\n",
    "print(f\"Size of the Additional structure database used as seed for compounds of interest: {df_Additional.shape[0]}\")\n",
    "print(f\"How many compounds can be promptly identified as compounds of interest (co-occurring in both databases): {df_Interest.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd3f60a",
   "metadata": {},
   "source": [
    "### Find MS2 Fragments from .mgf (GNPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "704924e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in: C:\\Users\\borge\\Documents\\DBsimilarity.py\\resources\n",
      "Batches loaded: ['Library-b0b1079fccb74a26aeddc992605f19bf-specs_ms']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch</th>\n",
       "      <th>scans</th>\n",
       "      <th>scan_number</th>\n",
       "      <th>precursor_mass</th>\n",
       "      <th>Fragments</th>\n",
       "      <th>n_fragments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Library-b0b1079fccb74a26aeddc992605f19bf-specs_ms</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>393.207</td>\n",
       "      <td>147.0802:100.0;171.0802:40.5;121.0645:40.5;107...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Library-b0b1079fccb74a26aeddc992605f19bf-specs_ms</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>393.208</td>\n",
       "      <td>147.0802:100.0;355.1909:73.2;237.1273:70.6;337...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Library-b0b1079fccb74a26aeddc992605f19bf-specs_ms</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>393.208</td>\n",
       "      <td>147.0802:100.0;355.1911:64.0;237.1274:63.8;171...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Library-b0b1079fccb74a26aeddc992605f19bf-specs_ms</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>393.208</td>\n",
       "      <td>147.0803:100.0;237.1274:64.9;355.1912:62.7;171...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Library-b0b1079fccb74a26aeddc992605f19bf-specs_ms</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>393.208</td>\n",
       "      <td>147.0802:100.0;237.1274:65.0;355.1912:62.3;171...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               batch scans  scan_number  precursor_mass                                          Fragments  n_fragments\n",
       "0  Library-b0b1079fccb74a26aeddc992605f19bf-specs_ms     1            1         393.207  147.0802:100.0;171.0802:40.5;121.0645:40.5;107...            5\n",
       "1  Library-b0b1079fccb74a26aeddc992605f19bf-specs_ms     2            2         393.208  147.0802:100.0;355.1909:73.2;237.1273:70.6;337...            5\n",
       "2  Library-b0b1079fccb74a26aeddc992605f19bf-specs_ms     3            3         393.208  147.0802:100.0;355.1911:64.0;237.1274:63.8;171...            5\n",
       "3  Library-b0b1079fccb74a26aeddc992605f19bf-specs_ms     4            4         393.208  147.0803:100.0;237.1274:64.9;355.1912:62.7;171...            5\n",
       "4  Library-b0b1079fccb74a26aeddc992605f19bf-specs_ms     5            5         393.208  147.0802:100.0;237.1274:65.0;355.1912:62.3;171...            5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes loaded: 259621\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>InchiKey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94850</td>\n",
       "      <td>CC(CN1CCOCC1)OC(=O)c1ccc(C(C)(C)C)cc1</td>\n",
       "      <td>BEXIDRCZUGWGPI-UHFFFAOYSA-N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103461</td>\n",
       "      <td>CC(=O)OC1(C)CC(C)C(=O)C(C(O)CC2CC(=O)NC(=O)C2)C1</td>\n",
       "      <td>UFDHNJJHPSGMFX-UHFFFAOYSA-N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>222897</td>\n",
       "      <td>CN(C)CCOC(=O)COc1ccc(Cl)cc1</td>\n",
       "      <td>XZTYGFHCIAKPGJ-UHFFFAOYSA-N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144738</td>\n",
       "      <td>Cc1ccc(-c2c(C(=O)N3CCN4C(=O)NC(=O)C4C3)scc2)cc1</td>\n",
       "      <td>HGPQJSIALUOWRP-UHFFFAOYSA-N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>152314</td>\n",
       "      <td>NC(=O)c1c(F)ccc(NC(=O)c2ccccc2OC(F)(F)F)c1</td>\n",
       "      <td>IOOZNCLKVQZBGI-UHFFFAOYSA-N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                            SMILES                     InchiKey\n",
       "0   94850             CC(CN1CCOCC1)OC(=O)c1ccc(C(C)(C)C)cc1  BEXIDRCZUGWGPI-UHFFFAOYSA-N\n",
       "1  103461  CC(=O)OC1(C)CC(C)C(=O)C(C(O)CC2CC(=O)NC(=O)C2)C1  UFDHNJJHPSGMFX-UHFFFAOYSA-N\n",
       "2  222897                       CN(C)CCOC(=O)COc1ccc(Cl)cc1  XZTYGFHCIAKPGJ-UHFFFAOYSA-N\n",
       "3  144738   Cc1ccc(-c2c(C(=O)N3CCN4C(=O)NC(=O)C4C3)scc2)cc1  HGPQJSIALUOWRP-UHFFFAOYSA-N\n",
       "4  152314        NC(=O)c1c(F)ccc(NC(=O)c2ccccc2OC(F)(F)F)c1  IOOZNCLKVQZBGI-UHFFFAOYSA-N"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# resolve ../resources relative to the current working directory\n",
    "RESOURCES_DIR = (Path.cwd().parent / \"resources\").resolve()\n",
    "print(\"Looking in:\", RESOURCES_DIR)\n",
    "\n",
    "spectra_by_batch = dbs.load_mgf_spectra(str(RESOURCES_DIR))\n",
    "print(\"Batches loaded:\", list(spectra_by_batch.keys())[:5])\n",
    "\n",
    "# Keeps up to 10 most intense fragment peaks per spectrum (after thresholding)\n",
    "# Only peaks with relative intensity ≥ 2% of the base peak are considered\n",
    "mgfdata_df = (\n",
    "    dbs.spectra_to_dataframe(\n",
    "        spectra_by_batch,\n",
    "        top_n=5,       # X: max number of fragment peaks to keep per spectrum\n",
    "        min_rel_pct=20.0 # Y: minimum relative intensity (%) vs. base peak\n",
    "    )\n",
    "    .rename(columns={\"fragments\": \"Fragments\"})  # optional, just cosmetic\n",
    ")\n",
    "\n",
    "display(mgfdata_df.head())\n",
    "\n",
    "# GraphML → DataFrame\n",
    "df_nodes = dbs.graphml_to_dataframe(\n",
    "    \"Library-b0b1079fccb74a26aeddc992605f19bf-network_singletons.graphml\",\n",
    "    resources_dir=RESOURCES_DIR,\n",
    "    write_csv=True)  # optional\n",
    "\n",
    "print(\"Nodes loaded:\", len(df_nodes))\n",
    "df_nodes = dbs.add_inchikey_from_structures(df_nodes[[\"id\", \"SMILES\"]])\n",
    "display(df_nodes.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c5a75c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch</th>\n",
       "      <th>scans</th>\n",
       "      <th>scan_number</th>\n",
       "      <th>precursor_mass</th>\n",
       "      <th>Fragments</th>\n",
       "      <th>n_fragments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>259616</th>\n",
       "      <td>Library-b0b1079fccb74a26aeddc992605f19bf-specs_ms</td>\n",
       "      <td>259617</td>\n",
       "      <td>259617</td>\n",
       "      <td>852.802</td>\n",
       "      <td>579.5811:100.0;551.5564:69.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259617</th>\n",
       "      <td>Library-b0b1079fccb74a26aeddc992605f19bf-specs_ms</td>\n",
       "      <td>259618</td>\n",
       "      <td>259618</td>\n",
       "      <td>852.802</td>\n",
       "      <td>579.5335:100.0;551.5022:62.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259618</th>\n",
       "      <td>Library-b0b1079fccb74a26aeddc992605f19bf-specs_ms</td>\n",
       "      <td>259619</td>\n",
       "      <td>259619</td>\n",
       "      <td>956.865</td>\n",
       "      <td>655.5887:100.0;607.5724:50.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259619</th>\n",
       "      <td>Library-b0b1079fccb74a26aeddc992605f19bf-specs_ms</td>\n",
       "      <td>259620</td>\n",
       "      <td>259620</td>\n",
       "      <td>956.865</td>\n",
       "      <td>655.5648:100.0;607.5649:66.9;95.0854:35.8;315....</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259620</th>\n",
       "      <td>Library-b0b1079fccb74a26aeddc992605f19bf-specs_ms</td>\n",
       "      <td>259621</td>\n",
       "      <td>259621</td>\n",
       "      <td>936.896</td>\n",
       "      <td>663.6571:100.0;635.6091:79.0;607.5424:37.8;579...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    batch   scans  scan_number  precursor_mass                                          Fragments  n_fragments\n",
       "259616  Library-b0b1079fccb74a26aeddc992605f19bf-specs_ms  259617       259617         852.802                       579.5811:100.0;551.5564:69.4            2\n",
       "259617  Library-b0b1079fccb74a26aeddc992605f19bf-specs_ms  259618       259618         852.802                       579.5335:100.0;551.5022:62.0            2\n",
       "259618  Library-b0b1079fccb74a26aeddc992605f19bf-specs_ms  259619       259619         956.865                       655.5887:100.0;607.5724:50.5            2\n",
       "259619  Library-b0b1079fccb74a26aeddc992605f19bf-specs_ms  259620       259620         956.865  655.5648:100.0;607.5649:66.9;95.0854:35.8;315....            5\n",
       "259620  Library-b0b1079fccb74a26aeddc992605f19bf-specs_ms  259621       259621         936.896  663.6571:100.0;635.6091:79.0;607.5424:37.8;579...            5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(mgfdata_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25457ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Compound identifier</th>\n",
       "      <th>Compound name</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Fragments</th>\n",
       "      <th>file_path</th>\n",
       "      <th>Compound name (unified)</th>\n",
       "      <th>additional_column_1</th>\n",
       "      <th>additional_column_2</th>\n",
       "      <th>InchiKey</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C(CC/C=C/C=C/[C@@H]1C([C@@H](C[C@H](C[C@H](C[C...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>akunolide D</td>\n",
       "      <td>akunolide D</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AALRUTPHSVMTFN-OGKHLYSKSA-N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CCCCCC(O)/C=C/CCCCCCCC(OCCO)=O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2-hydroxyethyl-11-hydroxyhexadec-9-enoate</td>\n",
       "      <td>2-hydroxyethyl-11-hydroxyhexadec-9-enoate</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AAXLHCBKRIITLB-JLHYYAGUSA-N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CyanoMetDB_1644</td>\n",
       "      <td>Mirabazole C</td>\n",
       "      <td>CC(C1=N[C@](C2=N[C@@](C3=N[C@@](C4=NC=CS4)(C)C...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mirabazole C</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>AAZNLXXTBVTBKQ-KSZLIROESA-N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CyanoMetDB_1430</td>\n",
       "      <td>Malyngamide T</td>\n",
       "      <td>CCCCCCC[C@@H](C/C=C/CCC(=O)NC/C(=C/Cl)/CC1=CC(...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Malyngamide T</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ABBPFXQJIWUCKF-CXRCMLCDSA-N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CyanoMetDB_1700</td>\n",
       "      <td>2,5-dimethyldodecanoic acid</td>\n",
       "      <td>CCCCCCCC(C)CC[C@@H](C)C(=O)O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2,5-dimethyldodecanoic acid</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ABQDDNHUZOOWMZ-ZGTCLIOFSA-N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Compound identifier                 Compound name                                             SMILES  Fragments                                  file_path  \\\n",
       "0                  NaN                          NaN  C(CC/C=C/C=C/[C@@H]1C([C@@H](C[C@H](C[C@H](C[C...        NaN                                akunolide D   \n",
       "1                  NaN                          NaN                     CCCCCC(O)/C=C/CCCCCCCC(OCCO)=O        NaN  2-hydroxyethyl-11-hydroxyhexadec-9-enoate   \n",
       "2      CyanoMetDB_1644                 Mirabazole C  CC(C1=N[C@](C2=N[C@@](C3=N[C@@](C4=NC=CS4)(C)C...        NaN                                        NaN   \n",
       "3      CyanoMetDB_1430                Malyngamide T  CCCCCCC[C@@H](C/C=C/CCC(=O)NC/C(=C/Cl)/CC1=CC(...        NaN                                        NaN   \n",
       "4      CyanoMetDB_1700  2,5-dimethyldodecanoic acid                       CCCCCCCC(C)CC[C@@H](C)C(=O)O        NaN                                        NaN   \n",
       "\n",
       "                     Compound name (unified)  additional_column_1  additional_column_2                     InchiKey   id  \n",
       "0                                akunolide D                    0                    1  AALRUTPHSVMTFN-OGKHLYSKSA-N  NaN  \n",
       "1  2-hydroxyethyl-11-hydroxyhexadec-9-enoate                    0                    1  AAXLHCBKRIITLB-JLHYYAGUSA-N  NaN  \n",
       "2                               Mirabazole C                    1                    0  AAZNLXXTBVTBKQ-KSZLIROESA-N  NaN  \n",
       "3                              Malyngamide T                    1                    0  ABBPFXQJIWUCKF-CXRCMLCDSA-N  NaN  \n",
       "4                2,5-dimethyldodecanoic acid                    1                    0  ABQDDNHUZOOWMZ-ZGTCLIOFSA-N  NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>merged_df rows</td>\n",
       "      <td>2709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>df_nodes rows</td>\n",
       "      <td>259621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>merged_df unique InchiKey</td>\n",
       "      <td>2688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>df_nodes unique InchiKey</td>\n",
       "      <td>29993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unique matches (intersection)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>unique union</td>\n",
       "      <td>32680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>row-level matches in merged_df</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>entries merged (left join merged_df→df_nodes)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>unique match rate vs merged_df</td>\n",
       "      <td>0.000372024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>unique match rate vs df_nodes</td>\n",
       "      <td>3.33411e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>row-level match rate in merged_df</td>\n",
       "      <td>0.00036914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>entries merged rate in merged_df</td>\n",
       "      <td>0.00036914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>merged_df duplicated InchiKey (keys)</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>df_nodes duplicated InchiKey (keys)</td>\n",
       "      <td>28505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           metric       value\n",
       "0                                  merged_df rows        2709\n",
       "1                                   df_nodes rows      259621\n",
       "2                       merged_df unique InchiKey        2688\n",
       "3                        df_nodes unique InchiKey       29993\n",
       "4                   unique matches (intersection)           1\n",
       "5                                    unique union       32680\n",
       "6                  row-level matches in merged_df           1\n",
       "7   entries merged (left join merged_df→df_nodes)           1\n",
       "8                  unique match rate vs merged_df 0.000372024\n",
       "9                   unique match rate vs df_nodes 3.33411e-05\n",
       "10              row-level match rate in merged_df  0.00036914\n",
       "11               entries merged rate in merged_df  0.00036914\n",
       "12           merged_df duplicated InchiKey (keys)          21\n",
       "13            df_nodes duplicated InchiKey (keys)       28505"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged_df_plus_nodes = dbs.merge_on_inchikey(merged_df, df_nodes, how=\"left\")\n",
    "display(merged_df_plus_nodes.head())\n",
    "\n",
    "summary, left_dups, right_dups, miss_left, miss_right = dbs.inchikey_match_report(\n",
    "    merged_df, df_nodes, left_name=\"merged_df\", right_name=\"df_nodes\")\n",
    "\n",
    "# count rows that actually matched something from df_nodes\n",
    "display(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "750a9577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'left_rows': 2713,\n",
       " 'right_rows': 259621,\n",
       " 'unique_ids': 5,\n",
       " 'unique_scans': 259621,\n",
       " 'matched_rows': 5,\n",
       " 'match_rate_rows': 0.0018429782528566164,\n",
       " 'unmatched_id_examples': []}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now to populate the Fragments column\n",
    "merged_final_frag, report = dbs.merge_nodes_with_mgf(\n",
    "    merged_df_plus_nodes,\n",
    "    mgfdata_df,\n",
    "    dedupe_mgf=True,\n",
    "    prefer_mgf_fragments=True,\n",
    "    drop_nan_fragments=True,   # set True if you want to remove rows without Fragments\n",
    ")\n",
    "display(report)\n",
    "merged_final_frag[[\"InchiKey\",\"precursor_mass\", \"scan_number\", \"Compound name (unified)\", \"Fragments\"]].to_csv(\"merged_fragments.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2dbc6cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name = \"your compound name\"\n",
    "\n",
    "mask = (\n",
    "    merged_df_plus_nodes[\"Compound name (unified)\"]\n",
    "      .astype(\"string\").str.strip().str.casefold()\n",
    "    == target_name.strip().casefold()\n",
    ")\n",
    "rows = merged_df_plus_nodes.loc[mask]\n",
    "\n",
    "# first row only (if you expect one)\n",
    "row = rows.iloc[0] if not rows.empty else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42240b87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'STOP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mSTOP\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'STOP' is not defined"
     ]
    }
   ],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cfe2bf",
   "metadata": {},
   "source": [
    "### Annotate structures with formula, exact mass, adduct m/z, InChI/InChIKey, and SLogP (customizable)\n",
    "\n",
    "This cell runs the all-in-one annotator on `merged_df` and writes an extended table to `CyanosNP2010-2023_extended.csv`. You can toggle each computed field and choose data sources (Mordred vs RDKit for logP), ion mass convention (proton vs hydrogen atom), numeric precision, and which **adduct columns** to emit.\n",
    "\n",
    "What you’ll get added (when enabled):\n",
    "\n",
    "* `MolFormula`, `MolWeight` (neutral exact mass)\n",
    "* Adduct m/z columns: `MolWeight-1H`, `MolWeight+1H`, `MolWeight+Na`, `MolWeight+K` (and optional `MolWeight+NH4`)\n",
    "* `Inchi`, `InchiKey`\n",
    "* `SLogP`\n",
    "\n",
    "Notes & tips:\n",
    "\n",
    "* `logp_source=\"mordred\"` falls back to RDKit if Mordred isn’t available.\n",
    "* `use_proton_mass=True` uses 1.007276466 for H⁺ / H⁻ (MS-friendly). Set `False` to use 1.007825032 (H atom).\n",
    "* `drop_invalid_smiles=True` removes rows that can’t be parsed by RDKit (keeps outputs clean).\n",
    "* Adjust `decimals` if you need more/less precision for m/z matching.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b1952a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully customized run\n",
    "merged_df2 = dbs.annotate_smiles_table(\n",
    "    merged_df,\n",
    "    smiles_col=\"SMILES\",\n",
    "    compute_inchi=True,\n",
    "    compute_inchikey=True,\n",
    "    compute_formula=True,\n",
    "    compute_exact_mass=True,\n",
    "    compute_adduct_columns=True,\n",
    "    compute_logp=True,\n",
    "    logp_source=\"mordred\",  # or \"rdkit\"\n",
    "    # Your column names → adducts (you can add/remove as you like)\n",
    "    adduct_columns={\n",
    "        \"MolWeight-1H\": \"[M-H]-\",\n",
    "        \"MolWeight+1H\": \"[M+H]+\",\n",
    "        \"MolWeight+Na\": \"[M+Na]+\",\n",
    "        \"MolWeight+K\":  \"[M+K]+\",\n",
    "        # \"MolWeight+NH4\": \"[M+NH4]+\",    # uncomment if desired\n",
    "    },\n",
    "    use_proton_mass=True,    # False -> use hydrogen atom mass (1.007825032)\n",
    "    decimals=6,\n",
    "    drop_invalid_smiles=True,\n",
    "    out_csv=f\"{Project}_extended.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbca20c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a151c65a",
   "metadata": {},
   "source": [
    "### Generate MS1 MassQL queries (one per compound) and save to a text file\n",
    "\n",
    "This cell builds **vendor-agnostic MassQL** queries that search MS1 spectra for each compound’s expected **adduct m/z** values (here: `[M+H]+`, `[M+Na]+`, `[M+K]+`, `[M+NH4]+`) within a **±ppm** tolerance and with a minimum **intensity percent**. It writes a numbered, human-readable list to `MS1_queries_by_compound.txt`, with one block per compound.\n",
    "\n",
    "Notes & tips:\n",
    "\n",
    "* `mass_col=\"MolWeight\"` should be the **neutral monoisotopic mass**; adduct m/z are computed from it.\n",
    "* Tune `ppm`, `intensity_percent`, and `decimals` to match your instrument and centroiding.\n",
    "* Set `separate_adducts=True` if you prefer **one query per adduct** instead of an OR list.\n",
    "* If names aren’t unique, consider prefixing with an internal ID to avoid ambiguity in the output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8808f3-e452-423f-bab6-ce2ebf77b03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build queries\n",
    "q_dict = dbs.generate_massql_queries(\n",
    "    merged_df2,\n",
    "    ppm=10,\n",
    "    intensity_percent=1,\n",
    "    decimals=5,\n",
    "    separate_adducts=False,\n",
    "    adducts=[\"[M+H]+\", \"[M+Na]+\", \"[M+K]+\", \"[M+NH4]+\", \"[M+2H]+2\"],\n",
    "    name_col=\"Compound name\",\n",
    "    mass_col=\"MolWeight\",)\n",
    "\n",
    "out_path = Path(\"MS1_queries_by_compound.txt\")\n",
    "with out_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    for i, (name, q) in enumerate(q_dict.items(), start=1):\n",
    "        f.write(f\"### {i}. {name} ###\\n{q}\\n\\n\")  # blank line between queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda9a917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build queries\n",
    "q_dict = dbs.generate_massqlPrec_queries(\n",
    "    merged_df2,\n",
    "    ppm=10,\n",
    "    intensity_percent=1,\n",
    "    decimals=5,\n",
    "    separate_adducts=False,\n",
    "    adducts=[\"[M+H]+\", \"[M+Na]+\", \"[M+K]+\", \"[M+NH4]+\", \"[M+2H]+2\"],\n",
    "    name_col=\"Compound name\",\n",
    "    mass_col=\"MolWeight\",)\n",
    "\n",
    "out_path = Path(\"MS1_queries_by_compound_Prec.txt\")\n",
    "with out_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    for i, (name, q) in enumerate(q_dict.items(), start=1):\n",
    "        f.write(f\"### {i}. {name} ###\\n{q}\\n\\n\")  # blank line between queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ac2edc",
   "metadata": {},
   "source": [
    "### Generate MS2 MassQL queries (precursor ± fragments) and save to a text file\n",
    "\n",
    "This cell creates **MS2** queries that combine:\n",
    "\n",
    "* a **precursor** constraint built from the neutral mass and the selected adducts (`[M+H]+`, `[M+Na]+`, `[M+K]+`, `[M+NH4]+`) with `ppm_prec`, and\n",
    "* an optional **product-ion** list from the `Fragments` column matched with `ppm_prod` and an `INTENSITYPERCENT` floor.\n",
    "\n",
    "Behavior & tips:\n",
    "\n",
    "* If a row’s `Fragments` is empty, the query is **precursor-only** (still valid for MS2 filtering).\n",
    "* Fragment values are cleaned (duplicates removed, non-numeric ignored), and zeros are dropped.\n",
    "* **Cardinality**: by default, requires **1–5** fragment matches (clamped to available fragments). You can override with `cardinality_min` / `cardinality_max`.\n",
    "* `decimals=4` controls how m/z values are rendered—adjust if your instrument resolution demands more/less precision.\n",
    "* Tune `ppm_prec` vs `ppm_prod`: product ions often tolerate slightly tighter ppm than precursors, depending on your setup.\n",
    "\n",
    "The result is written to `MS2_queries_by_compound.txt`, one numbered block per compound.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf52ac8-8553-44ca-be1b-a7feab9232dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build\n",
    "ms2_q = dbs.generate_massql_ms2_queries(\n",
    "    merged_df2,\n",
    "    name_col=\"Compound name\",\n",
    "    mass_col=\"MolWeight\",        # or \"Monoisotopic mass\"\n",
    "    fragments_col=\"Fragments\",\n",
    "    adducts=[\"[M+H]+\",\"[M+Na]+\",\"[M+K]+\",\"[M+NH4]+\", \"[M+2H]+2\"],\n",
    "    ppm_prec=10,\n",
    "    ppm_prod=10,\n",
    "    cardinality_min= 1,\n",
    "    cardinality_max= 5,\n",
    "    intensity_percent=5,\n",
    "    decimals=4)\n",
    "\n",
    "# Write\n",
    "out_path = Path(\"MS2_queries_by_compound.txt\")\n",
    "with out_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    for i, (name, q) in enumerate(ms2_q.items(), start=1):\n",
    "        f.write(f\"### {i}. {name} ###\\n{q}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25586c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peek a couple:\n",
    "for i, (k, v) in enumerate(ms2_q.items()):\n",
    "    print(v, end=\"\\n\\n\")\n",
    "    if i == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee83b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68884052",
   "metadata": {},
   "source": [
    "### Prepare a clean submission table for NPClassifier\n",
    "\n",
    "This cell exports the **minimal structure table** NPClassifier needs: a unique identifier (`InchiKey`) and the corresponding `SMILES`. The file is saved as `<Project>_for_NPClassifier.csv` with no index, ready to upload or batch process.\n",
    "\n",
    "Tips:\n",
    "\n",
    "* Consider deduplicating by `InchiKey` first to avoid repeated predictions.\n",
    "* Make sure all `SMILES` parse in RDKit (invalid rows can be removed earlier).\n",
    "* If you also want human-readable labels, you can include a `Compound name` column—extra columns are typically ignored by classifiers but remain useful for mapping results back.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc69b4d-b49b-44da-b93a-b921b2e12884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing the .csv file to be submitted to NPClassifier \n",
    "df_NPclassifier0 = merged_df2[[\"InchiKey\",\"SMILES\"]]\n",
    "df_NPclassifier0.to_csv(Project + '_for_NPClassifier.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b890b87",
   "metadata": {},
   "source": [
    "### Attach RDKit molecule objects (and fingerprints) to your table\n",
    "\n",
    "This cell converts each `SMILES` into an RDKit **Molecule** and adds it as a new `Molecule` column (with embedded fingerprints because `includeFingerprints=True`). Many downstream ops (fingerprints, similarity, drawing) expect this column.\n",
    "\n",
    "Notes & tips:\n",
    "\n",
    "* This operation **modifies `merged_df2` in place**.\n",
    "* It can be **memory-heavy** on large tables (molecules + fingerprints stored per row).\n",
    "* Your comment mentions `SMILES_parent`, but the code uses `SMILES`. If the source column is actually `SMILES_parent`, change the call to:\n",
    "\n",
    "  ```python\n",
    "  PandasTools.AddMoleculeColumnToFrame(merged_df2, 'SMILES_parent', 'Molecule', includeFingerprints=True)\n",
    "  ```\n",
    "* If you only need molecules (no fingerprints), set `includeFingerprints=False` to save memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1797e2e2-c4d3-417b-a751-85bdf65e30b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "# create the column 'Molecules' with the structures for each SMILES entree at the column 'SMILES_parent'\n",
    "PandasTools.AddMoleculeColumnToFrame(merged_df2,'SMILES','Molecule',includeFingerprints=True)\n",
    "print([str(x) for x in  merged_df2.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbe840b",
   "metadata": {},
   "source": [
    "### Compute an all-vs-all molecular similarity matrix (Morgan fingerprints)\n",
    "\n",
    "This cell builds a **square similarity matrix** between every pair of structures using **Morgan fingerprints** (radius = 2, nBits = 2048 by default) and the **Dice** metric. Requirements:\n",
    "\n",
    "* `merged_df2` must already contain an RDKit **`Molecule`** column and a unique **`InchiKey`** per row.\n",
    "* The output `sim_df` has rows/columns indexed by `InchiKey`, with a **diagonal of 1.0**.\n",
    "\n",
    "How to read/use it:\n",
    "\n",
    "* Each entry ∈ \\[0, 1] is a pairwise similarity; higher means more similar.\n",
    "* You can switch to **Tanimoto** by passing `metric=\"tanimoto\"`.\n",
    "* Tune structure granularity with `radius` (2–3 are common) and control hash space via `nbits` (default 2048 in the helper).\n",
    "\n",
    "Tips:\n",
    "\n",
    "* Consider **deduplicating** molecules before running to avoid redundant rows.\n",
    "* For large libraries, this is **O(n²)** in time/memory; filter first or compute similarities to a **subset/query set** if needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b35bb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming merged_df already has RDKit Mol objects in 'Molecule' and an 'InchiKey' column:\n",
    "sim_df = dbs.morgan_similarity_matrix(\n",
    "                      merged_df2, \n",
    "                      mol_col=\"Molecule\", \n",
    "                      id_col=\"InchiKey\", \n",
    "                      radius=2, \n",
    "                      metric=\"dice\")\n",
    "\n",
    "display(sim_df.head(2))\n",
    "print(f\"SimTablet2 is the square matrix (with a diagonal = 1, {sim_df.shape}) with all the similarities calculated between every pair of structures.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ad9b0b",
   "metadata": {},
   "source": [
    "### Build a similarity network, export edge list, and list isolated compounds\n",
    "\n",
    "This cell turns the all-vs-all similarity matrix into a **network**:\n",
    "\n",
    "* **Edges**: pairs with similarity **> 0.85** (strictly greater; equals are excluded by design).\n",
    "\n",
    "  * Output: `links_filtered` (columns: `SOURCE`, `TARGET`, `CORRELATION`), deduplicated and undirected.\n",
    "  * Saved as: `\"<Project>_DB_compounds_Similarity_0.85.csv\"` (semicolon-separated) if `save_csv=True`.\n",
    "* **Graph**: `G` is a NetworkX graph built from the edge list; use it for quick stats or to write GraphML/GEXF for Cytoscape/Gephi.\n",
    "* **Isolated nodes**: entries with **no edges above threshold** (i.e., chemically unique under current settings).\n",
    "\n",
    "  * Output: `isolated_nodes_df`, saved to `\"<Project>_isolated_nodes.csv\"` when `save_isolated_csv=True`.\n",
    "\n",
    "Notes & tips:\n",
    "\n",
    "* If you want the identity column to be human-readable (e.g., `Compound name` or `file_path`), set `identity_col` accordingly. Right now it’s `InchiKey`.\n",
    "* Make sure `metadata_df` points to the table that **contains** your identity column. If you annotated into `merged_df2`, pass `metadata_df=merged_df2`.\n",
    "* To **include** pairs with similarity exactly equal to the cutoff, either slightly lower `threshold` (e.g., `0.8499`) or change the helper to use `>=`.\n",
    "* Cytoscape import: load the edge CSV; choose `SOURCE`/`TARGET` as source/target and use `CORRELATION` as an edge attribute for styling or filtering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f352917",
   "metadata": {},
   "outputs": [],
   "source": [
    "links_filtered, G, isolated_nodes_df = dbs.build_similarity_network(\n",
    "            sim_df,\n",
    "            threshold=0.85,\n",
    "            project=Project,\n",
    "            save_csv=True,\n",
    "            csv_sep=\";\",\n",
    "            metadata_df=merged_df,       # or df_target if that’s where your identities live\n",
    "            id_col=\"InchiKey\",\n",
    "            identity_col=\"InchiKey\",    # change if your identity column is different\n",
    "            save_isolated_csv=True)\n",
    "\n",
    "# If you want to show InchiKey + file_path like you did:\n",
    "cols = [c for c in [\"InchiKey\", \"InchiKey\"] if c in isolated_nodes_df.columns]\n",
    "display(isolated_nodes_df[cols] if cols else isolated_nodes_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea771f1",
   "metadata": {},
   "source": [
    "### Export custom MS1 databases for MZmine (POS & NEG modes)\n",
    "\n",
    "This cell creates two **custom MS1 database** CSVs compatible with MZmine:\n",
    "\n",
    "* **POS** mode using the `[M+H]+` column (`MolWeight+1H`)\n",
    "* **NEG** mode using the `[M−H]−` column (`MolWeight-1H`)\n",
    "\n",
    "Each output has the columns (and order) MZmine expects:\n",
    "`ID, m/z, Retention Time, identity, Formula`\n",
    "\n",
    "What to know:\n",
    "\n",
    "* `identity_col` should be a stable identifier you’ll recognize inside MZmine (here we use `InchiKey`; you could use `Compound name` or a filename path).\n",
    "* `default_rt=0.0` sets a single retention time for all entries (fine for MS1 dereplication lists).\n",
    "* Filenames default to `\"<Project>_MZMine_CustomDB_POS.csv\"` and `\"<Project>_MZMine_CustomDB_NEG.csv\"` in your working folder.\n",
    "\n",
    "Tips:\n",
    "\n",
    "* Ensure `MolWeight+1H` and `MolWeight-1H` already exist (use the annotator cell). These typically use the **proton mass** (1.007276466), which is standard for MS.\n",
    "* You can refine later: add experiment-specific RTs per compound, or create separate DB files per subclass/taxon to speed matching.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc32e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS mode: [M+H]+\n",
    "df_mzmine_pos = dbs.make_mzmine_custom_db(\n",
    "        merged_df2,\n",
    "        mz_col=\"MolWeight+1H\",\n",
    "        formula_col=\"MolFormula\",\n",
    "        identity_col=\"InchiKey\",   # <— use a column that exists\n",
    "        default_rt=0.0,\n",
    "        project=Project,\n",
    "        mode=\"POS\",\n",
    "        save_csv=True,)\n",
    "\n",
    "# NEG mode: [M-H]-\n",
    "df_mzmine_neg = dbs.make_mzmine_custom_db(\n",
    "        merged_df2,\n",
    "        mz_col=\"MolWeight-1H\",\n",
    "        formula_col=\"MolFormula\",\n",
    "        identity_col=\"InchiKey\",\n",
    "        default_rt=0.0,\n",
    "        project=Project,\n",
    "        mode=\"NEG\",\n",
    "        save_csv=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d6b1bc",
   "metadata": {},
   "source": [
    "### Compute Mordred molecular descriptors (2D/3D) and save to CSV\n",
    "\n",
    "This cell generates a wide set of **Mordred descriptors** for each SMILES and writes them to `\"<Project>_DB_compounds_MordredDescriptors.csv\"` (semicolon-separated). The return value `info` reports how many **2D**, **3D**, and **total** descriptors are available in your environment.\n",
    "\n",
    "Notes & tips:\n",
    "\n",
    "* `ignore_3D=False` requests **3D descriptors**; unless your molecules already have embedded 3D coordinates, many 3D fields may be **NaN**.\n",
    "\n",
    "  * If you don’t need 3D (or don’t have conformers), set `ignore_3D=True` for a faster, denser table.\n",
    "* If you *do* want 3D, generate conformers first (RDKit: `AllChem.EmbedMolecule` + `AllChem.UFFOptimizeMolecule`) and pass those mols to the function.\n",
    "* Descriptor tables can be **large** (hundreds to thousands of columns). Plan memory accordingly.\n",
    "* Some Mordred/RDKit builds prefer **NumPy < 2**; if you hit import/runtime issues, pin the version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ca94d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MORDRED-Descriptors\n",
    "df_descriptors, info = dbs.compute_mordred_descriptors(\n",
    "        merged_df2,\n",
    "        smiles_col=\"SMILES\",\n",
    "        ignore_3D=False,         # set True if you want 2D-only\n",
    "        project=Project,         # used for filename\n",
    "        save_csv=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca765d87",
   "metadata": {},
   "source": [
    "### Cluster compounds with a Ward dendrogram, save the figure, and subset by cluster\n",
    "\n",
    "This cell performs **hierarchical clustering** on the Mordred descriptor matrix and draws a **Ward dendrogram**. The `color_threshold` both colors branch groups and—since `cut_distance=None`—acts as the **distance cut** to assign cluster IDs. With `run_agglomerative=True`, it also runs a matching **AgglomerativeClustering** to provide a complementary label set.\n",
    "\n",
    "Outputs:\n",
    "\n",
    "* **Figure** saved to `images/dendogram.png` (PNG) and displayed inline.\n",
    "* **CSV** of cluster labels saved with a project-prefixed name.\n",
    "* **`clusters`**: a `pd.Series` of hierarchical cluster IDs (you attach it to `merged_df2`).\n",
    "* Example subset: all rows with `cluster == 3`.\n",
    "\n",
    "Tips:\n",
    "\n",
    "* Ensure `df_descriptors` is the numeric descriptor table produced earlier (rows aligned to your metadata).\n",
    "* If you intended the standard spelling, change `filename=\"dendrogram.png\"` to avoid confusion later.\n",
    "* To control the number of clusters directly, lower `color_threshold` (tighter cut) or pass an explicit `cut_distance`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b6e859",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clusters, Z, fig, ax, df_clustered = dbs.dendrogram_and_cluster_descriptors(\n",
    "        df_descriptors,                    # table from Mordred\n",
    "        color_threshold=250000,\n",
    "        xlim=(0, 700000),\n",
    "        do_save_png=True,\n",
    "        save_dir=\"images\",\n",
    "        filename=\"dendogram.png\",\n",
    "        cut_distance=None,                 # None -> uses color_threshold\n",
    "        run_agglomerative=True,\n",
    "        metadata_df=merged_df,             # to fetch file_path (if present)\n",
    "        id_col=\"InchiKey\",\n",
    "        identity_col=\"file_path\",\n",
    "        project=Project,\n",
    "        save_cluster_csv=True)\n",
    "fig.show()\n",
    "\n",
    "# If you want the same “cluster = 3” subset:\n",
    "merged_df2[\"cluster\"] = clusters  # if not already added via write-back\n",
    "merged_dfX = merged_df2.loc[merged_df2[\"cluster\"] == 3, [\"cluster\"]].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977520ba",
   "metadata": {},
   "source": [
    "### Project the descriptor space to 2D with t-SNE and explore clusters interactively\n",
    "\n",
    "This cell uses **t-SNE** to compress the high-dimensional Mordred descriptor space into **2D** for visual exploration. Points are **colored by the Agglomerative cluster labels** (`df_clustered[\"Clust\"]`) and enriched with **hover info** (`file_path`, `cluster`, `Compound name`). The figure renders inline and is also saved as an interactive HTML at `images/t-sne.html` for sharing.\n",
    "\n",
    "Tips:\n",
    "\n",
    "* **Perplexity** must be sensible relative to sample size (rule of thumb: ≤ (n−1)/3). For small datasets, use 5–15; for larger, try 20–50.\n",
    "* Set `standardize=True` if descriptor scales differ markedly.\n",
    "* Results vary with initialization; add `random_state=0` for reproducibility if desired.\n",
    "* If colors appear mismatched, ensure the **index** of `df_clustered` aligns with `df_descriptors`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64a9236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_descriptors_values from the Mordred step (numeric only)\n",
    "proj, fig = dbs.tsne_projection_plot(\n",
    "        df_descriptors,                        # full DF; function picks numeric cols\n",
    "        metadata_df=merged_df2,                 # for hover columns\n",
    "        cluster_series=df_clustered[\"Clust\"],  # color by sklearn cluster labels\n",
    "        hover_cols=(\"file_path\", \"cluster\", \"Compound name\"),\n",
    "        standardize=False,                     # set True if scales differ a lot\n",
    "        perplexity=20,\n",
    "        out_html=\"images/t-sne.html\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8cf2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5721c6e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
